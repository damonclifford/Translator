{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentence Translator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnYvTsG9iIno",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f1704ee-9b48-453c-aba6-0e31d65dd6b0"
      },
      "source": [
        "import string\n",
        "import re\n",
        "from numpy import array, argmax, random, take\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "pd.set_option('display.max_colwidth', 200)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtRnERzcjJYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_text(filename):\n",
        "        # open the file\n",
        "        file = open(filename, mode='rt', encoding='utf-8')\n",
        "        \n",
        "        # read all text\n",
        "        text = file.read()\n",
        "        file.close()\n",
        "        return text\n",
        "\n",
        "def to_lines(text):\n",
        "      sents = text.strip().split('\\n')\n",
        "      sents = [i.split('\\t') for i in sents]\n",
        "      return sents"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueR9vj0suClw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = read_text(\"deu.txt\")\n",
        "deu_eng = to_lines(data)\n",
        "deu_eng = array(deu_eng)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRdf3uruuHur",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "8188d67f-fd72-4e7e-8eaa-195dfdbb4866"
      },
      "source": [
        "deu_eng = deu_eng[:100000,:2]\n",
        "deu_eng"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Go.', 'Geh.'],\n",
              "       ['Hi.', 'Hallo!'],\n",
              "       ['Hi.', 'Grüß Gott!'],\n",
              "       ...,\n",
              "       ['Why are you always so angry?',\n",
              "        'Warum sind Sie immer so ärgerlich?'],\n",
              "       ['Why are you always so angry?',\n",
              "        'Warum seid ihr immer so ärgerlich?'],\n",
              "       ['Why are you always so happy?',\n",
              "        'Warum seid ihr immer so glücklich?']], dtype='<U537')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct-0UYkwvI4j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "2135341f-45b8-44d5-edec-b1bafa4f0e0b"
      },
      "source": [
        "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)).lower() for s in deu_eng[:,0]]\n",
        "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)).lower() for s in deu_eng[:,1]]\n",
        "\n",
        "deu_eng"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['go', 'geh'],\n",
              "       ['hi', 'hallo'],\n",
              "       ['hi', 'grüß gott'],\n",
              "       ...,\n",
              "       ['why are you always so angry',\n",
              "        'warum sind sie immer so ärgerlich'],\n",
              "       ['why are you always so angry',\n",
              "        'warum seid ihr immer so ärgerlich'],\n",
              "       ['why are you always so happy',\n",
              "        'warum seid ihr immer so glücklich']], dtype='<U537')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwguToFLvbNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenization(lines):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBjTGygowABR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#english tokenizer \n",
        "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "\n",
        "eng_length = 8"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUHwxWmowgAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#deutsch tokenizer\n",
        "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
        "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
        "\n",
        "deu_length = 8"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2mXWLcMwwqC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_sequences(tokenizer, length, lines):\n",
        "         # integer encode sequences\n",
        "         seq = tokenizer.texts_to_sequences(lines)\n",
        "         # pad sequences with 0 values\n",
        "         seq = pad_sequences(seq, maxlen=length, padding='post')\n",
        "         return seq"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMx8lBNDzNk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX = encode_sequences(eng_tokenizer, deu_length, deu_eng[:, 0])\n",
        "trainY = encode_sequences(deu_tokenizer, eng_length, deu_eng[:, 1])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sea0K4Vazexo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build NMT model\n",
        "def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n",
        "      model = Sequential()\n",
        "      model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
        "      model.add(LSTM(units))\n",
        "      model.add(RepeatVector(out_timesteps))\n",
        "      model.add(LSTM(units, return_sequences=True))\n",
        "      model.add(Dense(out_vocab, activation='softmax'))\n",
        "      return model\n",
        "\n",
        "# model compilation\n",
        "model = define_model(eng_vocab_size, deu_vocab_size, eng_length, deu_length, 512)\n",
        "\n",
        "rms = optimizers.RMSprop(lr=0.001)\n",
        "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyw3aLDMzkkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8cead942-a14e-4d0f-d26f-85e8561b8161"
      },
      "source": [
        "filename = 'model.h1'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "# train model\n",
        "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n",
        "                    epochs=25, batch_size=512, validation_split = 0.2,callbacks=[checkpoint], \n",
        "                    verbose=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 80000 samples, validate on 20000 samples\n",
            "Epoch 1/25\n",
            "80000/80000 [==============================] - 34s 430us/step - loss: 3.8630 - val_loss: 4.5155\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.51552, saving model to model.h1\n",
            "Epoch 2/25\n",
            "80000/80000 [==============================] - 34s 422us/step - loss: 3.2354 - val_loss: 4.2569\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.51552 to 4.25689, saving model to model.h1\n",
            "Epoch 3/25\n",
            "80000/80000 [==============================] - 34s 431us/step - loss: 2.9519 - val_loss: 3.9770\n",
            "\n",
            "Epoch 00003: val_loss improved from 4.25689 to 3.97701, saving model to model.h1\n",
            "Epoch 4/25\n",
            "80000/80000 [==============================] - 35s 438us/step - loss: 2.6867 - val_loss: 3.7702\n",
            "\n",
            "Epoch 00004: val_loss improved from 3.97701 to 3.77022, saving model to model.h1\n",
            "Epoch 5/25\n",
            "80000/80000 [==============================] - 36s 445us/step - loss: 2.4560 - val_loss: 3.5860\n",
            "\n",
            "Epoch 00005: val_loss improved from 3.77022 to 3.58600, saving model to model.h1\n",
            "Epoch 6/25\n",
            "80000/80000 [==============================] - 35s 443us/step - loss: 2.2393 - val_loss: 3.4509\n",
            "\n",
            "Epoch 00006: val_loss improved from 3.58600 to 3.45094, saving model to model.h1\n",
            "Epoch 7/25\n",
            "80000/80000 [==============================] - 36s 444us/step - loss: 2.0437 - val_loss: 3.2935\n",
            "\n",
            "Epoch 00007: val_loss improved from 3.45094 to 3.29350, saving model to model.h1\n",
            "Epoch 8/25\n",
            "80000/80000 [==============================] - 36s 445us/step - loss: 1.8701 - val_loss: 3.2105\n",
            "\n",
            "Epoch 00008: val_loss improved from 3.29350 to 3.21047, saving model to model.h1\n",
            "Epoch 9/25\n",
            "80000/80000 [==============================] - 36s 444us/step - loss: 1.7191 - val_loss: 3.0669\n",
            "\n",
            "Epoch 00009: val_loss improved from 3.21047 to 3.06689, saving model to model.h1\n",
            "Epoch 10/25\n",
            "80000/80000 [==============================] - 35s 443us/step - loss: 1.5849 - val_loss: 2.9956\n",
            "\n",
            "Epoch 00010: val_loss improved from 3.06689 to 2.99562, saving model to model.h1\n",
            "Epoch 11/25\n",
            "80000/80000 [==============================] - 35s 443us/step - loss: 1.4657 - val_loss: 2.9220\n",
            "\n",
            "Epoch 00011: val_loss improved from 2.99562 to 2.92202, saving model to model.h1\n",
            "Epoch 12/25\n",
            "80000/80000 [==============================] - 36s 444us/step - loss: 1.3621 - val_loss: 2.8630\n",
            "\n",
            "Epoch 00012: val_loss improved from 2.92202 to 2.86302, saving model to model.h1\n",
            "Epoch 13/25\n",
            "80000/80000 [==============================] - 36s 445us/step - loss: 1.2683 - val_loss: 2.8153\n",
            "\n",
            "Epoch 00013: val_loss improved from 2.86302 to 2.81529, saving model to model.h1\n",
            "Epoch 14/25\n",
            "80000/80000 [==============================] - 35s 444us/step - loss: 1.1830 - val_loss: 2.8218\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 2.81529\n",
            "Epoch 15/25\n",
            "80000/80000 [==============================] - 35s 443us/step - loss: 1.1054 - val_loss: 2.7722\n",
            "\n",
            "Epoch 00015: val_loss improved from 2.81529 to 2.77216, saving model to model.h1\n",
            "Epoch 16/25\n",
            "80000/80000 [==============================] - 35s 443us/step - loss: 1.0361 - val_loss: 2.7469\n",
            "\n",
            "Epoch 00016: val_loss improved from 2.77216 to 2.74695, saving model to model.h1\n",
            "Epoch 17/25\n",
            "80000/80000 [==============================] - 36s 444us/step - loss: 0.9715 - val_loss: 2.7799\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 2.74695\n",
            "Epoch 18/25\n",
            "80000/80000 [==============================] - 36s 445us/step - loss: 0.9135 - val_loss: 2.7443\n",
            "\n",
            "Epoch 00018: val_loss improved from 2.74695 to 2.74430, saving model to model.h1\n",
            "Epoch 19/25\n",
            "80000/80000 [==============================] - 35s 444us/step - loss: 0.8607 - val_loss: 2.7315\n",
            "\n",
            "Epoch 00019: val_loss improved from 2.74430 to 2.73155, saving model to model.h1\n",
            "Epoch 20/25\n",
            "80000/80000 [==============================] - 35s 442us/step - loss: 0.8116 - val_loss: 2.7264\n",
            "\n",
            "Epoch 00020: val_loss improved from 2.73155 to 2.72639, saving model to model.h1\n",
            "Epoch 21/25\n",
            "80000/80000 [==============================] - 35s 443us/step - loss: 0.7664 - val_loss: 2.7512\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 2.72639\n",
            "Epoch 22/25\n",
            "80000/80000 [==============================] - 36s 444us/step - loss: 0.7260 - val_loss: 2.7479\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 2.72639\n",
            "Epoch 23/25\n",
            "80000/80000 [==============================] - 35s 443us/step - loss: 0.6865 - val_loss: 2.7715\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 2.72639\n",
            "Epoch 24/25\n",
            "80000/80000 [==============================] - 35s 442us/step - loss: 0.6494 - val_loss: 2.7815\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 2.72639\n",
            "Epoch 25/25\n",
            "80000/80000 [==============================] - 35s 443us/step - loss: 0.6156 - val_loss: 2.7946\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 2.72639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFcBXlDQ0WOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocessing function\n",
        "def preprocess(sentence):\n",
        "    sentence = sentence.translate(str.maketrans('', '', string.punctuation)).lower()\n",
        "    return sentence\n",
        "\n",
        "# function to get german words using tokens\n",
        "def get_word(n, tokenizer):\n",
        "      for word, index in tokenizer.word_index.items():\n",
        "          if index == n:\n",
        "              return word\n",
        "      return None\n",
        "\n",
        "#function to form sentences in deutsch using tokens \n",
        "def get_sentence(deu_list):\n",
        "    final = ''\n",
        "    for i in deu_list:\n",
        "        if i != 0:\n",
        "            word = get_word(i, deu_tokenizer)\n",
        "            final = final + str(word) + ' '\n",
        "    return final"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVZjP-sz7RE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to translate english sentence to deutsch sentence using \n",
        "#the functions defined above\n",
        "def translate(sentence):\n",
        "    sentence = preprocess(sentence)\n",
        "    a = encode_sequences(eng_tokenizer, eng_length, [sentence])\n",
        "    b = model.predict_classes(a)[0]\n",
        "    translation = get_sentence(b)\n",
        "    return translation"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P2XhIpu9br_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "df7fc1c4-26d0-41dd-db9f-251ee1a80f9b"
      },
      "source": [
        "translate('I am a man')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ich bin ein mann '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIeFfjZ09f-0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea3383b5-caf4-4f83-8d4e-07daa8891c78"
      },
      "source": [
        "translate(\"What are you doing?\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'was machst du '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAhOFiJb-xhi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bebca596-7c67-43b4-d4b0-d158bc0847e2"
      },
      "source": [
        "translate(\"I am drinking water\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ich trinke wasser '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiEgQh9d_nmo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "43e6a6db-3b69-4679-e9d4-2ab3f9eda458"
      },
      "source": [
        "translate(\"He is eating egg\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'er isst ein '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2mvsXxi_wMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9cf95e0f-6e78-4cfd-8bc7-ca7ac48c3271"
      },
      "source": [
        "translate(\"I am reading book\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ich lese ein buch '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYBvswDL_1ED",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "41ccb33a-028c-45ab-c2e1-41acf6ac75cd"
      },
      "source": [
        "translate(\"I love coffee\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ich liebe kaffee '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S3uiANv_5Ls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "71f939c8-8666-489e-fbab-21cc3aaeb363"
      },
      "source": [
        "translate(\"Where are you from?\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'wo kommt ihr her '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnXZQBKYE8Yk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "74297fda-9ed3-4716-ceb6-e253e8ea4e88"
      },
      "source": [
        "translate(\"How are you?\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'wie geht es '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOIUVwBpE8Uh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4cfafd85-44c2-4663-9446-a8e61d074db7"
      },
      "source": [
        "translate(\"Do you like Tea or Coffee\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'magst du tee kaffee kaffee '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-YfUhCfH5RC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "94d51e03-b280-41e1-ea5c-28764870741c"
      },
      "source": [
        "translate(\"I am drinking tea.\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ich trinke gerade '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IRFcvRwJD6c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b2c68f40-976f-4642-8700-f5d4259c5652"
      },
      "source": [
        "translate(\"The woman is pretty\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'die frau ist hübsch '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDKMQ0G9JHqq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c9551641-979c-4f7e-f30a-4f9f43f1003f"
      },
      "source": [
        "translate(\"I am very happy\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ich bin glücklich glücklich '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO0OSQdnJQsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}